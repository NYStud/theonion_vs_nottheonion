{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Models\n",
    "The intuition behind TF-IDF is that if a word appears multiple times in a document it should be more important; if it appears in fewer documents it might be important; and if it appears multiple times in a small subset of documents then it might be _very_ important. In this notebook, we will reapply the analysis from the previous notebook, but using TF-IDF to vectorize our titles. Since what we are doing is going to be virtually identical, we will only comment on things that differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:02.808256Z",
     "start_time": "2020-01-31T09:15:01.993379Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:03.354799Z",
     "start_time": "2020-01-31T09:15:02.810251Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, ComplementNB, BernoulliNB\n",
    "# Import CountVectorizer and TFIDFVectorizer from feature_extraction.text.\n",
    "from sklearn.feature_extraction.text import CountVectorizer,\\\n",
    "                                            TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:03.661038Z",
     "start_time": "2020-01-31T09:15:03.356794Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:03.670248Z",
     "start_time": "2020-01-31T09:15:03.662033Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_obj(obj, filename):\n",
    "    with open(filename + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(filename):\n",
    "    with open(filename + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:03.681192Z",
     "start_time": "2020-01-31T09:15:03.672216Z"
    }
   },
   "outputs": [],
   "source": [
    "DIR = \"C:\\\\Users\\\\AzNsAnTaGiN\\\\DSI\\\\Projects\\\\project_3\\\\data\\\\\"\n",
    "FILE1 = \"theonion\"\n",
    "FILE2 = \"nottheonion\"\n",
    "FILE3 = \"onionheadlines\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:03.928097Z",
     "start_time": "2020-01-31T09:15:03.683186Z"
    }
   },
   "outputs": [],
   "source": [
    "X_theonion = load_obj(DIR+FILE1+\"_df_clean\")\n",
    "X_nottheonion = load_obj(DIR+FILE2+\"_df_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:03.936624Z",
     "start_time": "2020-01-31T09:15:03.929651Z"
    }
   },
   "outputs": [],
   "source": [
    "X_theonion[\"is_onion\"] = 1\n",
    "X_nottheonion[\"is_onion\"] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating our samples and holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:04.130107Z",
     "start_time": "2020-01-31T09:15:03.938619Z"
    }
   },
   "outputs": [],
   "source": [
    "N=4000\n",
    "X_theonion_shuffled = X_theonion.sample(len(X_theonion))\n",
    "theonion_sample = X_theonion_shuffled.head(N)\n",
    "theonion_holdout = X_theonion_shuffled.tail(len(X_theonion_shuffled) - N)\n",
    "\n",
    "X_nottheonion_shuffled = X_nottheonion.sample(len(X_nottheonion))\n",
    "nottheonion_sample = X_nottheonion_shuffled.head(N)\n",
    "nottheonion_holdout = X_nottheonion_shuffled.tail(len(X_nottheonion_shuffled)-N)\n",
    "X_sample = pd.concat([theonion_sample, nottheonion_sample])\n",
    "X = pd.concat([X_theonion, X_nottheonion])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:04.481188Z",
     "start_time": "2020-01-31T09:15:04.133100Z"
    }
   },
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(ngram_range=(1,1))\n",
    "cvec.fit(theonion_sample[\"title\"])\n",
    "cvec.transform(theonion_sample[\"title\"])\n",
    "cvec_df = pd.DataFrame(cvec.transform(theonion_sample[\"title\"]).toarray(),\n",
    "                      columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:04.782372Z",
     "start_time": "2020-01-31T09:15:04.483163Z"
    }
   },
   "outputs": [],
   "source": [
    "cvec2 = CountVectorizer(ngram_range=(1,1))\n",
    "cvec2.fit(nottheonion_sample[\"title\"])\n",
    "cvec2.transform(nottheonion_sample[\"title\"])\n",
    "cvec2_df = pd.DataFrame(cvec2.transform(nottheonion_sample[\"title\"]).toarray(),\n",
    "                      columns=cvec2.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our stop-words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:04.787369Z",
     "start_time": "2020-01-31T09:15:04.784357Z"
    }
   },
   "outputs": [],
   "source": [
    "N = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:04.943949Z",
     "start_time": "2020-01-31T09:15:04.789346Z"
    }
   },
   "outputs": [],
   "source": [
    "theonion_top_words = cvec_df.sum().sort_values(ascending=False).index[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:05.076999Z",
     "start_time": "2020-01-31T09:15:04.945927Z"
    }
   },
   "outputs": [],
   "source": [
    "nottheonion_top_words = cvec2_df.sum().sort_values(ascending=False).index[:N]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF + Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No custom tokenizing, no lemmatizing, no stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:30.587782Z",
     "start_time": "2020-01-31T09:15:05.078994Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='...\n",
       "       5.21400829e+01, 5.72236766e+01, 6.28029144e+01, 6.89261210e+01,\n",
       "       7.56463328e+01, 8.30217568e+01, 9.11162756e+01, 1.00000000e+02]),\n",
       "                                      class_weight=None, cv=None, dual=False,\n",
       "                                      fit_intercept=True, intercept_scaling=1.0,\n",
       "                                      l1_ratios=None, max_iter=1000,\n",
       "                                      multi_class='auto', n_jobs=None,\n",
       "                                      penalty='l2', random_state=None,\n",
       "                                      refit=True, scoring=None, solver='lbfgs',\n",
       "                                      tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_sample[\"title\"], X_sample[\"is_onion\"])\n",
    "pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()),\n",
    "    (\"logreg\", LogisticRegressionCV(Cs=np.logspace(-2,2,100), max_iter=1000))])\n",
    "     \n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:36.878854Z",
     "start_time": "2020-01-31T09:15:30.589776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.976"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7985"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8097210113339146"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7949465804761033"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pipe.score(X_train, y_train))\n",
    "display(pipe.score(X_test, y_test))\n",
    "display(pipe.score(theonion_holdout[\"title\"], theonion_holdout[\"is_onion\"]))\n",
    "display(pipe.score(nottheonion_holdout[\"title\"], nottheonion_holdout[\"is_onion\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter searching ft. ngrams, finite features, stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:49.866431Z",
     "start_time": "2020-01-31T09:15:36.880848Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(strip_accents=\"unicode\")),\n",
    "#     (\"norm\", Normalizer()),\n",
    "    (\"logreg\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "rand_search = RandomizedSearchCV(pipe,\n",
    "                                 n_jobs=-2,\n",
    "                                 n_iter=50,\n",
    "                                 param_distributions={\n",
    "    \"logreg__C\": np.logspace(-1,1,100),\n",
    "    \"tfidf__max_df\": [.99, 1],\n",
    "    \"tfidf__min_df\": [0, 0.01],\n",
    "    \"tfidf__stop_words\": [None, [i for i in theonion_top_words if i in nottheonion_top_words]],\n",
    "    \"tfidf__ngram_range\": [(1,1), (1,2)],\n",
    "    \"tfidf__max_features\": [None, 10, 50, 100, 250, 500, 1000, 2000, 5000, 10000, 20000, 50000]\n",
    "})\n",
    "rand_search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:49.877377Z",
     "start_time": "2020-01-31T09:15:49.868401Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.99, max_features=None,\n",
       "                                 min_df=0, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents='unicode',\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('logreg',\n",
       "                 LogisticRegression(C=0.739072203352578, class_weight=None,\n",
       "                                    dual=False, fit_intercept=True,\n",
       "                                    intercept_scaling=1, l1_ratio=None,\n",
       "                                    max_iter=1000, multi_class='auto',\n",
       "                                    n_jobs=None, penalty='l2',\n",
       "                                    random_state=None, solver='lbfgs',\n",
       "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:50.056406Z",
     "start_time": "2020-01-31T09:15:49.879371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9133333333333333"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:50.104283Z",
     "start_time": "2020-01-31T09:15:50.058401Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7825"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:50.201766Z",
     "start_time": "2020-01-31T09:15:50.106274Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7968613775065388"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.score(theonion_holdout[\"title\"], theonion_holdout[\"is_onion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:57.809658Z",
     "start_time": "2020-01-31T09:15:50.202764Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7829018988256375"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.score(nottheonion_holdout[\"title\"], nottheonion_holdout[\"is_onion\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a marginal improvement over our naive model, but it's worth noting that we finish training this model in half the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer + Naive Bayes\n",
    "\n",
    "In the following section, we apply a variety of Naive Bayes models to our CountVectorized titles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVec + MultinomialNB\n",
    "### Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:57.953290Z",
     "start_time": "2020-01-31T09:15:57.812663Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('mnb',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()),\n",
    "    (\"mnb\", MultinomialNB())\n",
    "])\n",
    "     \n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:16:04.216326Z",
     "start_time": "2020-01-31T09:15:57.957263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9546666666666667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8045"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8256320836965998"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7918902515390025"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pipe.score(X_train, y_train))\n",
    "display(pipe.score(X_test, y_test))\n",
    "display(pipe.score(theonion_holdout[\"title\"], theonion_holdout[\"is_onion\"]))\n",
    "display(pipe.score(nottheonion_holdout[\"title\"], nottheonion_holdout[\"is_onion\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomizedSearchCV'd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:16:15.366195Z",
     "start_time": "2020-01-31T09:16:04.218321Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(strip_accents=\"unicode\")),\n",
    "    (\"mnb\", MultinomialNB())\n",
    "])\n",
    "\n",
    "rand_search = RandomizedSearchCV(pipe,\n",
    "                                 n_jobs=-2,\n",
    "                                 n_iter=50,\n",
    "                                 param_distributions={\n",
    "    \"mnb__alpha\": np.linspace(0,1,11),\n",
    "    \"tfidf__max_df\": [.99, 1],\n",
    "    \"tfidf__min_df\": [0, 0.01],\n",
    "    \"tfidf__stop_words\": [None, [i for i in theonion_top_words if i in nottheonion_top_words]],\n",
    "    \"tfidf__ngram_range\": [(1,1), (1,2)],\n",
    "    \"tfidf__max_features\": [None, 10, 50, 100, 250, 500, 1000, 2000, 5000, 10000, 20000, 50000]\n",
    "})\n",
    "rand_search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:16:15.375109Z",
     "start_time": "2020-01-31T09:16:15.368139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.99,\n",
       "                                 max_features=50000, min_df=0,\n",
       "                                 ngram_range=(1, 2), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents='unicode',\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('mnb',\n",
       "                 MultinomialNB(alpha=0.2, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:16:27.169318Z",
     "start_time": "2020-01-31T09:16:15.377104Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9993333333333333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8185"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8236704446381866"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7888242887833451"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(rand_search.score(X_train, y_train))\n",
    "display(rand_search.score(X_test, y_test))\n",
    "display(rand_search.score(theonion_holdout[\"title\"], theonion_holdout[\"is_onion\"]))\n",
    "display(rand_search.score(nottheonion_holdout[\"title\"], nottheonion_holdout[\"is_onion\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVec + ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:16:27.298996Z",
     "start_time": "2020-01-31T09:16:27.171313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('cnb',\n",
       "                 ComplementNB(alpha=1.0, class_prior=None, fit_prior=True,\n",
       "                              norm=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()),\n",
    "    (\"cnb\", ComplementNB())\n",
    "])\n",
    "     \n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:16:33.521135Z",
     "start_time": "2020-01-31T09:16:27.301989Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.955"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.807"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8227986050566696"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7970901051049605"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pipe.score(X_train, y_train))\n",
    "display(pipe.score(X_test, y_test))\n",
    "display(pipe.score(theonion_holdout[\"title\"], theonion_holdout[\"is_onion\"]))\n",
    "display(pipe.score(nottheonion_holdout[\"title\"], nottheonion_holdout[\"is_onion\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:16:43.436886Z",
     "start_time": "2020-01-31T09:16:33.523130Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(strip_accents=\"unicode\")),\n",
    "    (\"cnb\", ComplementNB())\n",
    "])\n",
    "\n",
    "rand_search = RandomizedSearchCV(pipe,\n",
    "                                 n_jobs=-2,\n",
    "                                 n_iter=50,\n",
    "                                 param_distributions={\n",
    "    \"cnb__alpha\": np.linspace(0,1,11),\n",
    "    \"tfidf__max_df\": [.99, 1],\n",
    "    \"tfidf__min_df\": [0, 0.01],\n",
    "    \"tfidf__stop_words\": [None, [i for i in theonion_top_words if i in nottheonion_top_words]],\n",
    "    \"tfidf__ngram_range\": [(1,1), (1,2)],\n",
    "    \"tfidf__max_features\": [None, 10, 50, 100, 250, 500, 1000, 2000, 5000, 10000, 20000, 50000]\n",
    "})\n",
    "rand_search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:16:54.574604Z",
     "start_time": "2020-01-31T09:16:43.437868Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9395"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.815"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8121185701830863"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.798788065625572"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(rand_search.score(X_train, y_train))\n",
    "display(rand_search.score(X_test, y_test))\n",
    "display(rand_search.score(theonion_holdout[\"title\"], theonion_holdout[\"is_onion\"]))\n",
    "display(rand_search.score(nottheonion_holdout[\"title\"], nottheonion_holdout[\"is_onion\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVec + BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:16:54.700841Z",
     "start_time": "2020-01-31T09:16:54.576589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('bnb',\n",
       "                 BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None,\n",
       "                             fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()),\n",
    "    (\"bnb\", BernoulliNB())\n",
    "])\n",
    "     \n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:17:00.953060Z",
     "start_time": "2020-01-31T09:16:54.702823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9558333333333333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.807"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8129904097646034"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8115191568482"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pipe.score(X_train, y_train))\n",
    "display(pipe.score(X_test, y_test))\n",
    "display(pipe.score(theonion_holdout[\"title\"], theonion_holdout[\"is_onion\"]))\n",
    "display(pipe.score(nottheonion_holdout[\"title\"], nottheonion_holdout[\"is_onion\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:17:11.820431Z",
     "start_time": "2020-01-31T09:17:00.955055Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(strip_accents=\"unicode\")),\n",
    "    (\"bnb\", BernoulliNB())\n",
    "])\n",
    "\n",
    "rand_search = RandomizedSearchCV(pipe,\n",
    "                                 n_jobs=-2,\n",
    "                                 n_iter=50,\n",
    "                                 param_distributions={\n",
    "    \"bnb__alpha\": np.linspace(0,1,11),\n",
    "    \"tfidf__max_df\": [.99, 1],\n",
    "    \"tfidf__min_df\": [0, 0.01],\n",
    "    \"tfidf__stop_words\": [None, [i for i in theonion_top_words if i in nottheonion_top_words]],\n",
    "    \"tfidf__ngram_range\": [(1,1), (1,2)],\n",
    "    \"tfidf__max_features\": [None, 10, 50, 100, 250, 500, 1000, 2000, 5000, 10000, 20000, 50000]\n",
    "})\n",
    "rand_search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:17:23.181619Z",
     "start_time": "2020-01-31T09:17:11.822346Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9046666666666666"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8055"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7813862249346121"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8149512047090105"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(rand_search.score(X_train, y_train))\n",
    "display(rand_search.score(X_test, y_test))\n",
    "display(rand_search.score(theonion_holdout[\"title\"], theonion_holdout[\"is_onion\"]))\n",
    "display(rand_search.score(nottheonion_holdout[\"title\"], nottheonion_holdout[\"is_onion\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with our CountVectorized models, our BernoulliNB models were slighty better than the others, but it's hard to tell if its a statistically significant difference. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
