{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "SVMs are supposed to be realtively well-performing on high-dimensional data. We'll fit a few and see how we feel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T11:55:50.271875Z",
     "start_time": "2020-01-31T11:55:50.267884Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T11:55:50.633563Z",
     "start_time": "2020-01-31T11:55:50.628577Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, ComplementNB, BernoulliNB\n",
    "# Import CountVectorizer and TFIDFVectorizer from feature_extraction.text.\n",
    "from sklearn.feature_extraction.text import CountVectorizer,\\\n",
    "                                            TfidfVectorizer\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T11:55:50.848794Z",
     "start_time": "2020-01-31T11:55:50.843685Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T11:55:51.047449Z",
     "start_time": "2020-01-31T11:55:51.043459Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_obj(obj, filename):\n",
    "    with open(filename + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(filename):\n",
    "    with open(filename + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T11:55:51.303129Z",
     "start_time": "2020-01-31T11:55:51.300136Z"
    }
   },
   "outputs": [],
   "source": [
    "DIR = \"C:\\\\Users\\\\AzNsAnTaGiN\\\\DSI\\\\Projects\\\\project_3\\\\data\\\\\"\n",
    "FILE1 = \"theonion\"\n",
    "FILE2 = \"nottheonion\"\n",
    "FILE3 = \"onionheadlines\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T11:24:48.244067Z",
     "start_time": "2020-01-31T11:24:48.034649Z"
    }
   },
   "outputs": [],
   "source": [
    "X_theonion = load_obj(DIR+FILE1+\"_df_clean\")\n",
    "X_nottheonion = load_obj(DIR+FILE2+\"_df_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T11:24:48.255038Z",
     "start_time": "2020-01-31T11:24:48.247061Z"
    }
   },
   "outputs": [],
   "source": [
    "X_theonion[\"is_onion\"] = 1\n",
    "X_nottheonion[\"is_onion\"] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating our samples and holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T11:24:49.416126Z",
     "start_time": "2020-01-31T11:24:49.227630Z"
    }
   },
   "outputs": [],
   "source": [
    "N=4000\n",
    "X_theonion_shuffled = X_theonion.sample(len(X_theonion))\n",
    "theonion_sample = X_theonion_shuffled.head(N)\n",
    "theonion_holdout = X_theonion_shuffled.tail(len(X_theonion_shuffled) - N)\n",
    "\n",
    "X_nottheonion_shuffled = X_nottheonion.sample(len(X_nottheonion))\n",
    "nottheonion_sample = X_nottheonion_shuffled.head(N)\n",
    "nottheonion_holdout = X_nottheonion_shuffled.tail(len(X_nottheonion_shuffled)-N)\n",
    "X_sample = pd.concat([theonion_sample, nottheonion_sample])\n",
    "X = pd.concat([X_theonion, X_nottheonion])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our stop-words list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:04.787369Z",
     "start_time": "2020-01-31T09:15:04.784357Z"
    }
   },
   "outputs": [],
   "source": [
    "N = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:04.943949Z",
     "start_time": "2020-01-31T09:15:04.789346Z"
    }
   },
   "outputs": [],
   "source": [
    "theonion_top_words = cvec_df.sum().sort_values(ascending=False).index[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:05.076999Z",
     "start_time": "2020-01-31T09:15:04.945927Z"
    }
   },
   "outputs": [],
   "source": [
    "nottheonion_top_words = cvec2_df.sum().sort_values(ascending=False).index[:N]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF + SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T11:26:55.252452Z",
     "start_time": "2020-01-31T11:26:50.036399Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('svc',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_sample[\"title\"], X_sample[\"is_onion\"])\n",
    "pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()),\n",
    "    (\"svc\", SVC())])\n",
    "     \n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T11:31:31.467144Z",
     "start_time": "2020-01-31T11:26:55.254446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9968333333333333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7965"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8040540540540541"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8117335093110857"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pipe.score(X_train, y_train))\n",
    "display(pipe.score(X_test, y_test))\n",
    "display(pipe.score(theonion_holdout[\"title\"], theonion_holdout[\"is_onion\"]))\n",
    "display(pipe.score(nottheonion_holdout[\"title\"], nottheonion_holdout[\"is_onion\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T11:48:25.403827Z",
     "start_time": "2020-01-31T11:46:53.437560Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(strip_accents=\"unicode\")),\n",
    "#     (\"norm\", Normalizer()),\n",
    "    (\"svc\", SVC())\n",
    "])\n",
    "\n",
    "rand_search = RandomizedSearchCV(pipe,\n",
    "                                 n_jobs=-2,\n",
    "                                 n_iter=50,\n",
    "                                 param_distributions={\n",
    "#     \"logreg__C\": np.logspace(-1,1,100),\n",
    "    \"tfidf__max_df\": [.99, 1],\n",
    "    \"tfidf__min_df\": [0, 0.01],\n",
    "#     \"tfidf__stop_words\": [None, [i for i in theonion_top_words if i in nottheonion_top_words]],\n",
    "    \"tfidf__ngram_range\": [(1,1), (1,2)],\n",
    "    \"tfidf__max_features\": [None, 10, 50, 100, 250, 500, 1000, 2000, 5000, 10000, 20000, 50000]\n",
    "})\n",
    "rand_search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T11:48:25.416605Z",
     "start_time": "2020-01-31T11:48:25.406619Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=0.99,\n",
       "                                 max_features=20000, min_df=0,\n",
       "                                 ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents='unicode',\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('svc',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T11:53:17.233117Z",
     "start_time": "2020-01-31T11:48:25.419585Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9965"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.796"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8038360941586749"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8118322559512914"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(rand_search.score(X_train, y_train))\n",
    "display(rand_search.score(X_test, y_test))\n",
    "display(rand_search.score(theonion_holdout[\"title\"], theonion_holdout[\"is_onion\"]))\n",
    "display(rand_search.score(nottheonion_holdout[\"title\"], nottheonion_holdout[\"is_onion\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lord would you look at those execution times! 5 minutes, on average. Presumably if I reduced my feature space SVM would be happier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
